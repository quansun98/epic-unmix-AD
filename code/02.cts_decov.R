library(bMINDlocal)
library(Matrix)
library(tidyverse)
require(matrixcalc)

# load pre-processed Rdata generated by script 01 
load("snref_bulk.RData")
ls()

# read estimated cell type fraction file
frac = read.table("Est.prop.new_640samples_nodup.txt", row.names = 1, header = T)
frac = as.matrix(frac)

bulk = bulk[rownames(bulk) %in% rownames(sc_ref),]
dim(bulk)

cell_types = colnames(frac)
index = sc_meta$cell_type %in% cell_types
sc_ref = sc_ref[,index]
sc_meta = sc_meta[index,]
dim(sc_ref)
dim(sc_meta)
# n_gene = 15097

# read pre-selected gene-list
ct = "Mic"
gene_list = read.table("preselect_comb_genelist_FINAL.txt", header = F) %>%
  filter(V2 == ct)

bulk = bulk[order(rownames(bulk)), order(colnames(bulk))]
sc_ref = sc_ref[order(rownames(sc_ref)),]

bulk_sub = bulk[rownames(bulk) %in% gene_list$V1, colnames(bulk) %in% rownames(frac)]
sc_ref = sc_ref[rownames(sc_ref) %in% rownames(bulk_sub),]

# get the first prior from scRNAseq data
prior = get_prior(sc_ref, meta_sc = sc_meta)

# read in phenotype file to further filter samples
phenotype <- read_tsv("pheno_reID_processed.txt",col_names = T)
frac = frac[rownames(frac) %in% colnames(bulk_sub) , order(colnames(frac))]
frac = frac[rownames(frac) %in% as.vector(phenotype$ID), ]
frac = frac[order(rownames(frac)),]
phenotype = phenotype[as.vector(phenotype$ID) %in% rownames(frac),]
phenotype = phenotype[order(as.vector(phenotype$ID)),]

bulk_sub = bulk_sub[rownames(bulk_sub) %in% rownames(prior$profile), colnames(bulk_sub) %in% rownames(frac)]

# sanity check
sum(colnames(bulk_sub) != rownames(frac))
sum(rownames(bulk_sub) != rownames(prior$profile))

# covariates information
covariate = phenotype %>% select(-ID,-cogdx) %>% as.matrix()
rownames(covariate) = as.vector(phenotype$ID)
covariate = covariate[order(rownames(covariate) %in% rownames(frac)),]
sum(colnames(bulk_sub) != rownames(covariate))
phenotype = phenotype %>% mutate(ID = paste0("X", ID))

# log2 transformation
bulk_sub = log2(bulk_sub + 1)

# first-round of bayesian inference, include covariates
tmp.post = bmind_de(bulk_sub, frac = frac, profile = prior$profile, covariance = prior$cov, covariate = covariate, nu = 0.5, noRE = F, seed = 1)

tmp.bulk = bulk_sub
out=c()

# get new prior
n_gene = dim(tmp.post$A)[1]
n_ct = dim(tmp.post$A)[2]
n_sample = dim(tmp.post$A)[3]

bp = apply(tmp.post$A, c(1,2), mean) 
bp_cov = array(NA, dim = c(n_gene, n_ct, n_ct))
rownames(bp_cov) = rownames(tmp.post$A)
colnames(bp_cov) = colnames(tmp.post$A)
for(i in 1:n_gene) {
    tmp.cov = cov(t(tmp.post$A[i,,] + 0.1), use = 'pairwise')
    if(is.positive.definite(tmp.cov)){
       bp_cov[i,,] = tmp.cov
    }
}

na_index = is.na(bp_cov[,1,1])
bp_cov = bp_cov[!na_index,,]
bp = bp[!na_index,]
new_bulk_sub = tmp.bulk[rownames(tmp.bulk) %in% rownames(bp_cov),]
tmp.bulk = new_bulk_sub

# second-round of Bayesian inference, no covariates involved (the estimated CTS profiles in the last step already removed
#   covariates effects
# The parameter nu also increased a bit 
epic_unmix = bMIND(tmp.bulk, frac = frac , profile = bp, covariance = bp_cov, nu = 0.6, seed = 1)

# write the estimated CTS 
for(j in 1:5){
write.table(epic_unmix$A[,j,],paste0("epic_unmix_",colnames(epic_unmix$A)[j],"_out.txt"), col.names = T, row.names = T, quote = F, sep = "\t")
}

#saveRDS(epic_unmix, "epic_unmix_out.rds") 

